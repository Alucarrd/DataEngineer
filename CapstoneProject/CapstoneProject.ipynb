{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "For this project, I pulled the data from the AWS S3 and store them into RedShift database through a star schema.  This schema is designed to answer the question on where the immigrants were coming from and where do they go in US.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "from datetime import datetime, timedelta\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I want to display all 28 columns in the notebook\n",
    "pd.set_option('display.max_columns', 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "I used the immigration and the city demographics dataset provided by Udacity for this project.  \n",
    "Once the data's read into the pandas dataframe, I then push it to Postgres.  \n",
    "\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? \n",
    "\n",
    "The immigration dataset is provided by US National Tourism and Trade Office.  And the city demographic dataset is coming from OpenSoft.\n",
    "\n",
    "The immigration dataset contains the entry logs into the US borders.\n",
    "\n",
    "The city demographic dataset contains information about the demographic in the US cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "\n",
    "IMMIGRATION_CHUNK_SIZE = 500000\n",
    "IMMIGRATION_DATA_FILES = [\n",
    "    '../../data/18-83510-I94-Data-2016/i94_jan16_sub.sas7bdat',\n",
    "    '../../data/18-83510-I94-Data-2016/i94_feb16_sub.sas7bdat',\n",
    "    '../../data/18-83510-I94-Data-2016/i94_mar16_sub.sas7bdat',\n",
    "    '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat',\n",
    "    '../../data/18-83510-I94-Data-2016/i94_may16_sub.sas7bdat',\n",
    "    '../../data/18-83510-I94-Data-2016/i94_jun16_sub.sas7bdat',\n",
    "    '../../data/18-83510-I94-Data-2016/i94_jul16_sub.sas7bdat',\n",
    "    '../../data/18-83510-I94-Data-2016/i94_aug16_sub.sas7bdat',\n",
    "    '../../data/18-83510-I94-Data-2016/i94_sep16_sub.sas7bdat',\n",
    "    '../../data/18-83510-I94-Data-2016/i94_oct16_sub.sas7bdat',\n",
    "    '../../data/18-83510-I94-Data-2016/i94_nov16_sub.sas7bdat',\n",
    "    '../../data/18-83510-I94-Data-2016/i94_dec16_sub.sas7bdat'\n",
    "]\n",
    "\n",
    "HEADER_FILE = 'I94_SAS_Labels_Descriptions.SAS'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading one immigration file to explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = IMMIGRATION_DATA_FILES[0]\n",
    "iterator = pd.read_sas(\n",
    "    filename, 'sas7bdat', encoding=\"ISO-8859-1\", chunksize=IMMIGRATION_CHUNK_SIZE\n",
    ")\n",
    "df = next(iterator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>BOS</td>\n",
       "      <td>20465.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>346608285.0</td>\n",
       "      <td>424</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>BOS</td>\n",
       "      <td>20465.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>346627585.0</td>\n",
       "      <td>424</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>BOS</td>\n",
       "      <td>20469.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CT</td>\n",
       "      <td>20480.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>07152016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AF</td>\n",
       "      <td>381092385.0</td>\n",
       "      <td>338</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>BOS</td>\n",
       "      <td>20469.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CT</td>\n",
       "      <td>20499.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>07152016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AF</td>\n",
       "      <td>381087885.0</td>\n",
       "      <td>338</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>BOS</td>\n",
       "      <td>20469.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CT</td>\n",
       "      <td>20499.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>07152016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AF</td>\n",
       "      <td>381078685.0</td>\n",
       "      <td>338</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    7.0  2016.0     1.0   101.0   101.0     BOS  20465.0      1.0      MA   \n",
       "1    8.0  2016.0     1.0   101.0   101.0     BOS  20465.0      1.0      MA   \n",
       "2    9.0  2016.0     1.0   101.0   101.0     BOS  20469.0      1.0      CT   \n",
       "3   10.0  2016.0     1.0   101.0   101.0     BOS  20469.0      1.0      CT   \n",
       "4   11.0  2016.0     1.0   101.0   101.0     BOS  20469.0      1.0      CT   \n",
       "\n",
       "   depdate  i94bir  i94visa  count dtadfile visapost occup entdepa entdepd  \\\n",
       "0      NaN    20.0      3.0    1.0      NaN      NaN   NaN       T     NaN   \n",
       "1      NaN    20.0      3.0    1.0      NaN      NaN   NaN       T     NaN   \n",
       "2  20480.0    17.0      2.0    1.0      NaN      NaN   NaN       T       N   \n",
       "3  20499.0    45.0      2.0    1.0      NaN      NaN   NaN       T       N   \n",
       "4  20499.0    12.0      2.0    1.0      NaN      NaN   NaN       T       N   \n",
       "\n",
       "  entdepu matflag  biryear   dtaddto gender insnum airline       admnum fltno  \\\n",
       "0     NaN     NaN   1996.0       D/S      M    NaN      LH  346608285.0   424   \n",
       "1     NaN     NaN   1996.0       D/S      M    NaN      LH  346627585.0   424   \n",
       "2     NaN       M   1999.0  07152016      F    NaN      AF  381092385.0   338   \n",
       "3     NaN       M   1971.0  07152016      F    NaN      AF  381087885.0   338   \n",
       "4     NaN       M   2004.0  07152016      M    NaN      AF  381078685.0   338   \n",
       "\n",
       "  visatype  \n",
       "0       F1  \n",
       "1       F1  \n",
       "2       B2  \n",
       "3       B2  \n",
       "4       B2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499970</th>\n",
       "      <td>1152121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499971</th>\n",
       "      <td>1152122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499972</th>\n",
       "      <td>1152123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499973</th>\n",
       "      <td>1152124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499974</th>\n",
       "      <td>1152125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499975</th>\n",
       "      <td>1152126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499976</th>\n",
       "      <td>1152127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499977</th>\n",
       "      <td>1152128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499978</th>\n",
       "      <td>1152129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499979</th>\n",
       "      <td>1152130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499980</th>\n",
       "      <td>1152132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499981</th>\n",
       "      <td>1152133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499982</th>\n",
       "      <td>1152139.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499983</th>\n",
       "      <td>1152147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499984</th>\n",
       "      <td>1152148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499985</th>\n",
       "      <td>1152149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499986</th>\n",
       "      <td>1152150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499987</th>\n",
       "      <td>1152151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499988</th>\n",
       "      <td>1152152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499989</th>\n",
       "      <td>1152153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499990</th>\n",
       "      <td>1152154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499991</th>\n",
       "      <td>1152157.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499992</th>\n",
       "      <td>1152160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499993</th>\n",
       "      <td>1152161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499994</th>\n",
       "      <td>1152166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>1152167.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>1152168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>1152181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>1152182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>1152183.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            cicid\n",
       "0             7.0\n",
       "1             8.0\n",
       "2             9.0\n",
       "3            10.0\n",
       "4            11.0\n",
       "5            12.0\n",
       "6            15.0\n",
       "7            17.0\n",
       "8            18.0\n",
       "9            20.0\n",
       "10           21.0\n",
       "11           22.0\n",
       "12           23.0\n",
       "13           24.0\n",
       "14           25.0\n",
       "15           28.0\n",
       "16           29.0\n",
       "17           30.0\n",
       "18           32.0\n",
       "19           33.0\n",
       "20           36.0\n",
       "21           37.0\n",
       "22           40.0\n",
       "23           41.0\n",
       "24           42.0\n",
       "25           43.0\n",
       "26           44.0\n",
       "27           46.0\n",
       "28           47.0\n",
       "29           48.0\n",
       "...           ...\n",
       "499970  1152121.0\n",
       "499971  1152122.0\n",
       "499972  1152123.0\n",
       "499973  1152124.0\n",
       "499974  1152125.0\n",
       "499975  1152126.0\n",
       "499976  1152127.0\n",
       "499977  1152128.0\n",
       "499978  1152129.0\n",
       "499979  1152130.0\n",
       "499980  1152132.0\n",
       "499981  1152133.0\n",
       "499982  1152139.0\n",
       "499983  1152147.0\n",
       "499984  1152148.0\n",
       "499985  1152149.0\n",
       "499986  1152150.0\n",
       "499987  1152151.0\n",
       "499988  1152152.0\n",
       "499989  1152153.0\n",
       "499990  1152154.0\n",
       "499991  1152157.0\n",
       "499992  1152160.0\n",
       "499993  1152161.0\n",
       "499994  1152166.0\n",
       "499995  1152167.0\n",
       "499996  1152168.0\n",
       "499997  1152181.0\n",
       "499998  1152182.0\n",
       "499999  1152183.0\n",
       "\n",
       "[500000 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verify if cicid is the primary key\n",
    "df[['cicid']].groupby(['cicid']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2891, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_df = pd.read_csv('us-cities-demographics.csv', delimiter=';')\n",
    "print(city_df.shape)\n",
    "city_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "Upon inspecting the immigration data, few issues were identified.\n",
    "\n",
    "1. Bad birth year under the i94bir column.  Since the report's made in 2016, any birthday year after 2016 will be replaced to NULL.  And any year outside of the 1900 - 2006 will also be replaced with NULL value.\n",
    "\n",
    "2. Since the data's divided into multiple files, we need to ensure the columns from each file are consistent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put small dataframe from each month into a list\n",
    "small_list = []\n",
    "for fname in IMMIGRATION_DATA_FILES:\n",
    "    small_iterator = pd.read_sas(fname, 'sas7bdat', encoding='ISO-8859-1', chunksize=20)\n",
    "    small_list.append(next(small_iterator))\n",
    "\n",
    "#create a dictionary map for each month to list of the columns\n",
    "column_names_by_files = {t[0].split('/')[-1].split('_')[1][:3]: list(t[1].columns.values)\n",
    "                        for t in zip(IMMIGRATION_DATA_FILES, small_list)\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jan': ['cicid',\n",
       "  'i94yr',\n",
       "  'i94mon',\n",
       "  'i94cit',\n",
       "  'i94res',\n",
       "  'i94port',\n",
       "  'arrdate',\n",
       "  'i94mode',\n",
       "  'i94addr',\n",
       "  'depdate',\n",
       "  'i94bir',\n",
       "  'i94visa',\n",
       "  'count',\n",
       "  'dtadfile',\n",
       "  'visapost',\n",
       "  'occup',\n",
       "  'entdepa',\n",
       "  'entdepd',\n",
       "  'entdepu',\n",
       "  'matflag',\n",
       "  'biryear',\n",
       "  'dtaddto',\n",
       "  'gender',\n",
       "  'insnum',\n",
       "  'airline',\n",
       "  'admnum',\n",
       "  'fltno',\n",
       "  'visatype'],\n",
       " 'feb': ['cicid',\n",
       "  'i94yr',\n",
       "  'i94mon',\n",
       "  'i94cit',\n",
       "  'i94res',\n",
       "  'i94port',\n",
       "  'arrdate',\n",
       "  'i94mode',\n",
       "  'i94addr',\n",
       "  'depdate',\n",
       "  'i94bir',\n",
       "  'i94visa',\n",
       "  'count',\n",
       "  'dtadfile',\n",
       "  'visapost',\n",
       "  'occup',\n",
       "  'entdepa',\n",
       "  'entdepd',\n",
       "  'entdepu',\n",
       "  'matflag',\n",
       "  'biryear',\n",
       "  'dtaddto',\n",
       "  'gender',\n",
       "  'insnum',\n",
       "  'airline',\n",
       "  'admnum',\n",
       "  'fltno',\n",
       "  'visatype'],\n",
       " 'mar': ['cicid',\n",
       "  'i94yr',\n",
       "  'i94mon',\n",
       "  'i94cit',\n",
       "  'i94res',\n",
       "  'i94port',\n",
       "  'arrdate',\n",
       "  'i94mode',\n",
       "  'i94addr',\n",
       "  'depdate',\n",
       "  'i94bir',\n",
       "  'i94visa',\n",
       "  'count',\n",
       "  'dtadfile',\n",
       "  'visapost',\n",
       "  'occup',\n",
       "  'entdepa',\n",
       "  'entdepd',\n",
       "  'entdepu',\n",
       "  'matflag',\n",
       "  'biryear',\n",
       "  'dtaddto',\n",
       "  'gender',\n",
       "  'insnum',\n",
       "  'airline',\n",
       "  'admnum',\n",
       "  'fltno',\n",
       "  'visatype'],\n",
       " 'apr': ['cicid',\n",
       "  'i94yr',\n",
       "  'i94mon',\n",
       "  'i94cit',\n",
       "  'i94res',\n",
       "  'i94port',\n",
       "  'arrdate',\n",
       "  'i94mode',\n",
       "  'i94addr',\n",
       "  'depdate',\n",
       "  'i94bir',\n",
       "  'i94visa',\n",
       "  'count',\n",
       "  'dtadfile',\n",
       "  'visapost',\n",
       "  'occup',\n",
       "  'entdepa',\n",
       "  'entdepd',\n",
       "  'entdepu',\n",
       "  'matflag',\n",
       "  'biryear',\n",
       "  'dtaddto',\n",
       "  'gender',\n",
       "  'insnum',\n",
       "  'airline',\n",
       "  'admnum',\n",
       "  'fltno',\n",
       "  'visatype'],\n",
       " 'may': ['cicid',\n",
       "  'i94yr',\n",
       "  'i94mon',\n",
       "  'i94cit',\n",
       "  'i94res',\n",
       "  'i94port',\n",
       "  'arrdate',\n",
       "  'i94mode',\n",
       "  'i94addr',\n",
       "  'depdate',\n",
       "  'i94bir',\n",
       "  'i94visa',\n",
       "  'count',\n",
       "  'dtadfile',\n",
       "  'visapost',\n",
       "  'occup',\n",
       "  'entdepa',\n",
       "  'entdepd',\n",
       "  'entdepu',\n",
       "  'matflag',\n",
       "  'biryear',\n",
       "  'dtaddto',\n",
       "  'gender',\n",
       "  'insnum',\n",
       "  'airline',\n",
       "  'admnum',\n",
       "  'fltno',\n",
       "  'visatype'],\n",
       " 'jun': ['cicid',\n",
       "  'i94yr',\n",
       "  'i94mon',\n",
       "  'i94cit',\n",
       "  'i94res',\n",
       "  'i94port',\n",
       "  'arrdate',\n",
       "  'i94mode',\n",
       "  'i94addr',\n",
       "  'depdate',\n",
       "  'i94bir',\n",
       "  'i94visa',\n",
       "  'count',\n",
       "  'validres',\n",
       "  'delete_days',\n",
       "  'delete_mexl',\n",
       "  'delete_dup',\n",
       "  'delete_visa',\n",
       "  'delete_recdup',\n",
       "  'dtadfile',\n",
       "  'visapost',\n",
       "  'occup',\n",
       "  'entdepa',\n",
       "  'entdepd',\n",
       "  'entdepu',\n",
       "  'matflag',\n",
       "  'biryear',\n",
       "  'dtaddto',\n",
       "  'gender',\n",
       "  'insnum',\n",
       "  'airline',\n",
       "  'admnum',\n",
       "  'fltno',\n",
       "  'visatype'],\n",
       " 'jul': ['cicid',\n",
       "  'i94yr',\n",
       "  'i94mon',\n",
       "  'i94cit',\n",
       "  'i94res',\n",
       "  'i94port',\n",
       "  'arrdate',\n",
       "  'i94mode',\n",
       "  'i94addr',\n",
       "  'depdate',\n",
       "  'i94bir',\n",
       "  'i94visa',\n",
       "  'count',\n",
       "  'dtadfile',\n",
       "  'visapost',\n",
       "  'occup',\n",
       "  'entdepa',\n",
       "  'entdepd',\n",
       "  'entdepu',\n",
       "  'matflag',\n",
       "  'biryear',\n",
       "  'dtaddto',\n",
       "  'gender',\n",
       "  'insnum',\n",
       "  'airline',\n",
       "  'admnum',\n",
       "  'fltno',\n",
       "  'visatype'],\n",
       " 'aug': ['cicid',\n",
       "  'i94yr',\n",
       "  'i94mon',\n",
       "  'i94cit',\n",
       "  'i94res',\n",
       "  'i94port',\n",
       "  'arrdate',\n",
       "  'i94mode',\n",
       "  'i94addr',\n",
       "  'depdate',\n",
       "  'i94bir',\n",
       "  'i94visa',\n",
       "  'count',\n",
       "  'dtadfile',\n",
       "  'visapost',\n",
       "  'occup',\n",
       "  'entdepa',\n",
       "  'entdepd',\n",
       "  'entdepu',\n",
       "  'matflag',\n",
       "  'biryear',\n",
       "  'dtaddto',\n",
       "  'gender',\n",
       "  'insnum',\n",
       "  'airline',\n",
       "  'admnum',\n",
       "  'fltno',\n",
       "  'visatype'],\n",
       " 'sep': ['cicid',\n",
       "  'i94yr',\n",
       "  'i94mon',\n",
       "  'i94cit',\n",
       "  'i94res',\n",
       "  'i94port',\n",
       "  'arrdate',\n",
       "  'i94mode',\n",
       "  'i94addr',\n",
       "  'depdate',\n",
       "  'i94bir',\n",
       "  'i94visa',\n",
       "  'count',\n",
       "  'dtadfile',\n",
       "  'visapost',\n",
       "  'occup',\n",
       "  'entdepa',\n",
       "  'entdepd',\n",
       "  'entdepu',\n",
       "  'matflag',\n",
       "  'biryear',\n",
       "  'dtaddto',\n",
       "  'gender',\n",
       "  'insnum',\n",
       "  'airline',\n",
       "  'admnum',\n",
       "  'fltno',\n",
       "  'visatype'],\n",
       " 'oct': ['cicid',\n",
       "  'i94yr',\n",
       "  'i94mon',\n",
       "  'i94cit',\n",
       "  'i94res',\n",
       "  'i94port',\n",
       "  'arrdate',\n",
       "  'i94mode',\n",
       "  'i94addr',\n",
       "  'depdate',\n",
       "  'i94bir',\n",
       "  'i94visa',\n",
       "  'count',\n",
       "  'dtadfile',\n",
       "  'visapost',\n",
       "  'occup',\n",
       "  'entdepa',\n",
       "  'entdepd',\n",
       "  'entdepu',\n",
       "  'matflag',\n",
       "  'biryear',\n",
       "  'dtaddto',\n",
       "  'gender',\n",
       "  'insnum',\n",
       "  'airline',\n",
       "  'admnum',\n",
       "  'fltno',\n",
       "  'visatype'],\n",
       " 'nov': ['cicid',\n",
       "  'i94yr',\n",
       "  'i94mon',\n",
       "  'i94cit',\n",
       "  'i94res',\n",
       "  'i94port',\n",
       "  'arrdate',\n",
       "  'i94mode',\n",
       "  'i94addr',\n",
       "  'depdate',\n",
       "  'i94bir',\n",
       "  'i94visa',\n",
       "  'count',\n",
       "  'dtadfile',\n",
       "  'visapost',\n",
       "  'occup',\n",
       "  'entdepa',\n",
       "  'entdepd',\n",
       "  'entdepu',\n",
       "  'matflag',\n",
       "  'biryear',\n",
       "  'dtaddto',\n",
       "  'gender',\n",
       "  'insnum',\n",
       "  'airline',\n",
       "  'admnum',\n",
       "  'fltno',\n",
       "  'visatype'],\n",
       " 'dec': ['cicid',\n",
       "  'i94yr',\n",
       "  'i94mon',\n",
       "  'i94cit',\n",
       "  'i94res',\n",
       "  'i94port',\n",
       "  'arrdate',\n",
       "  'i94mode',\n",
       "  'i94addr',\n",
       "  'depdate',\n",
       "  'i94bir',\n",
       "  'i94visa',\n",
       "  'count',\n",
       "  'dtadfile',\n",
       "  'visapost',\n",
       "  'occup',\n",
       "  'entdepa',\n",
       "  'entdepd',\n",
       "  'entdepu',\n",
       "  'matflag',\n",
       "  'biryear',\n",
       "  'dtaddto',\n",
       "  'gender',\n",
       "  'insnum',\n",
       "  'airline',\n",
       "  'admnum',\n",
       "  'fltno',\n",
       "  'visatype']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names_by_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_values([['jan', 'feb', 'mar', 'apr', 'may', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec'], ['jun']])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list of column names as key and the values are list of the month\n",
    "column_names_by_files_reversed = defaultdict(list)\n",
    "for k, v in column_names_by_files.items():\n",
    "    column_names_by_files_reversed[','.join(v)].append(k)\n",
    "print(len(column_names_by_files_reversed))\n",
    "column_names_by_files_reversed.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looks like June has some problem.  More investigation.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 vs 34\n",
      "('cicid', 'cicid')\n",
      "('i94yr', 'i94yr')\n",
      "('i94mon', 'i94mon')\n",
      "('i94cit', 'i94cit')\n",
      "('i94res', 'i94res')\n",
      "('i94port', 'i94port')\n",
      "('arrdate', 'arrdate')\n",
      "('i94mode', 'i94mode')\n",
      "('i94addr', 'i94addr')\n",
      "('depdate', 'depdate')\n",
      "('i94bir', 'i94bir')\n",
      "('i94visa', 'i94visa')\n",
      "('count', 'count')\n",
      "('dtadfile', 'validres')\n",
      "('visapost', 'delete_days')\n",
      "('occup', 'delete_mexl')\n",
      "('entdepa', 'delete_dup')\n",
      "('entdepd', 'delete_visa')\n",
      "('entdepu', 'delete_recdup')\n",
      "('matflag', 'dtadfile')\n",
      "('biryear', 'visapost')\n",
      "('dtaddto', 'occup')\n",
      "('gender', 'entdepa')\n",
      "('insnum', 'entdepd')\n",
      "('airline', 'entdepu')\n",
      "('admnum', 'matflag')\n",
      "('fltno', 'biryear')\n",
      "('visatype', 'dtaddto')\n"
     ]
    }
   ],
   "source": [
    "normal_months = list(small_list[0].columns.values)\n",
    "problem_june = list(small_list[5].columns.values)\n",
    "print('{} vs {}'.format(len(normal_months), len(problem_june)))\n",
    "for zipped in (zip(normal_months, problem_june)):\n",
    "    print(zipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_months == [correct_column for correct_column in problem_june if not (correct_column.startswith('delete_') or correct_column =='validres')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like for some reason, the month of june has additional columns that was not prepared correctly.  We just need to make sure we exclude them at the time of insert.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>Irvine</td>\n",
       "      <td>California</td>\n",
       "      <td>34.6</td>\n",
       "      <td>125411.0</td>\n",
       "      <td>131516.0</td>\n",
       "      <td>256927</td>\n",
       "      <td>5532.0</td>\n",
       "      <td>116366.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>CA</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>Irvine</td>\n",
       "      <td>California</td>\n",
       "      <td>34.6</td>\n",
       "      <td>125411.0</td>\n",
       "      <td>131516.0</td>\n",
       "      <td>256927</td>\n",
       "      <td>5532.0</td>\n",
       "      <td>116366.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>8670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>Irvine</td>\n",
       "      <td>California</td>\n",
       "      <td>34.6</td>\n",
       "      <td>125411.0</td>\n",
       "      <td>131516.0</td>\n",
       "      <td>256927</td>\n",
       "      <td>5532.0</td>\n",
       "      <td>116366.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>CA</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>19266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2295</th>\n",
       "      <td>Irvine</td>\n",
       "      <td>California</td>\n",
       "      <td>34.6</td>\n",
       "      <td>125411.0</td>\n",
       "      <td>131516.0</td>\n",
       "      <td>256927</td>\n",
       "      <td>5532.0</td>\n",
       "      <td>116366.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>CA</td>\n",
       "      <td>White</td>\n",
       "      <td>127358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>Irvine</td>\n",
       "      <td>California</td>\n",
       "      <td>34.6</td>\n",
       "      <td>125411.0</td>\n",
       "      <td>131516.0</td>\n",
       "      <td>256927</td>\n",
       "      <td>5532.0</td>\n",
       "      <td>116366.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>CA</td>\n",
       "      <td>Asian</td>\n",
       "      <td>126499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        City       State  Median Age  Male Population  Female Population  \\\n",
       "635   Irvine  California        34.6         125411.0           131516.0   \n",
       "1040  Irvine  California        34.6         125411.0           131516.0   \n",
       "1290  Irvine  California        34.6         125411.0           131516.0   \n",
       "2295  Irvine  California        34.6         125411.0           131516.0   \n",
       "2484  Irvine  California        34.6         125411.0           131516.0   \n",
       "\n",
       "      Total Population  Number of Veterans  Foreign-born  \\\n",
       "635             256927              5532.0      116366.0   \n",
       "1040            256927              5532.0      116366.0   \n",
       "1290            256927              5532.0      116366.0   \n",
       "2295            256927              5532.0      116366.0   \n",
       "2484            256927              5532.0      116366.0   \n",
       "\n",
       "      Average Household Size State Code                               Race  \\\n",
       "635                     2.73         CA  American Indian and Alaska Native   \n",
       "1040                    2.73         CA          Black or African-American   \n",
       "1290                    2.73         CA                 Hispanic or Latino   \n",
       "2295                    2.73         CA                              White   \n",
       "2484                    2.73         CA                              Asian   \n",
       "\n",
       "       Count  \n",
       "635      799  \n",
       "1040    8670  \n",
       "1290   19266  \n",
       "2295  127358  \n",
       "2484  126499  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Exploring the city demographic data\n",
    "#Looking at one city sample:\n",
    "city_df[city_df['City'] == 'Irvine'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# City data exploration task 2\n",
    "#Check to see if population adds up to total\n",
    "#and check of any of the category is > Total Population\n",
    "for _, row in city_df.iterrows():\n",
    "    if pd.notnull(row['Male Population']):\n",
    "        assert row['Male Population'] + row['Female Population'] == row['Total Population']\n",
    "    if pd.notnull(row['Number of Veterans']):\n",
    "        assert row['Number of Veterans'] <= row['Total Population']\n",
    "    if pd.notnull(row['Foreign-born']):\n",
    "        assert row['Foreign-born'] <= row['Total Population']\n",
    "    if pd.notnull(row['Count']):\n",
    "        assert row['Count'] <= row['Total Population']\n",
    "    for numbered_column in ['Male Population', 'Female Population', 'Total Population', 'Number of Veterans', 'Foreign-born', 'Count']:\n",
    "        assert pd.isnull(row[numbered_column]) or row[numbered_column] > 0\n",
    "\n",
    "\n",
    "#looks like the data exploration task #2 passed without any issue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>Texas</td>\n",
       "      <td>125876</td>\n",
       "      <td>147900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Akron</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>197553</td>\n",
       "      <td>210305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alafaya</td>\n",
       "      <td>Florida</td>\n",
       "      <td>85264</td>\n",
       "      <td>115476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alameda</td>\n",
       "      <td>California</td>\n",
       "      <td>78614</td>\n",
       "      <td>89174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albany</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>71109</td>\n",
       "      <td>73478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      City       State  Total Population   Count\n",
       "0  Abilene       Texas            125876  147900\n",
       "1    Akron        Ohio            197553  210305\n",
       "2  Alafaya     Florida             85264  115476\n",
       "3  Alameda  California             78614   89174\n",
       "4   Albany     Georgia             71109   73478"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#City data exploration task 3\n",
    "#Check to see if race adds up to total\n",
    "sub_df = city_df[['City', 'State', 'Total Population', 'Count']]\n",
    "grouped = sub_df.groupby(['City', 'State', 'Total Population']).sum().reset_index()\n",
    "grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayamón Puerto Rico 170259 169155\n",
      "Caguas Puerto Rico 77008 76973\n",
      "Mayagüez Puerto Rico 66581 65756\n",
      "New Bedford Massachusetts 94959 93321\n",
      "Ponce Puerto Rico 121583 120705\n",
      "San Juan Puerto Rico 342237 342042\n",
      "South Jordan Utah 66639 66205\n"
     ]
    }
   ],
   "source": [
    "#Let's look at if Count always sums up to >= Total Population\n",
    "\n",
    "for _, row in grouped.iterrows():\n",
    "    if pd.notnull(row['Total Population']) and row['Count'] < row['Total Population']:\n",
    "        print(row['City'], row['State'], row['Total Population'], row['Count'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the places with discrepancy is mostly in places lacked diversity.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the state level of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State Code</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Foreign-born</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>61055672.0</td>\n",
       "      <td>62388681.0</td>\n",
       "      <td>123444353</td>\n",
       "      <td>37059662.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>TX</td>\n",
       "      <td>34862194.0</td>\n",
       "      <td>35691659.0</td>\n",
       "      <td>70553853</td>\n",
       "      <td>14498054.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NY</td>\n",
       "      <td>23422799.0</td>\n",
       "      <td>25579256.0</td>\n",
       "      <td>49002055</td>\n",
       "      <td>17186873.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FL</td>\n",
       "      <td>15461937.0</td>\n",
       "      <td>16626425.0</td>\n",
       "      <td>32306132</td>\n",
       "      <td>7845566.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>IL</td>\n",
       "      <td>10943864.0</td>\n",
       "      <td>11570526.0</td>\n",
       "      <td>22514390</td>\n",
       "      <td>4632600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   State Code  Male Population  Female Population  Total Population  \\\n",
       "4          CA       61055672.0         62388681.0         123444353   \n",
       "44         TX       34862194.0         35691659.0          70553853   \n",
       "34         NY       23422799.0         25579256.0          49002055   \n",
       "9          FL       15461937.0         16626425.0          32306132   \n",
       "14         IL       10943864.0         11570526.0          22514390   \n",
       "\n",
       "    Foreign-born  \n",
       "4     37059662.0  \n",
       "44    14498054.0  \n",
       "34    17186873.0  \n",
       "9      7845566.0  \n",
       "14     4632600.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = city_df[['State Code', 'Male Population', 'Female Population', 'Total Population', 'Foreign-born']]\n",
    "state_df = sub_df.groupby(['State Code']).sum().reset_index()\n",
    "print(state_df.shape)\n",
    "state_df.sort_values(by=['Total Population'], ascending=False).head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there isn't much we need to clean on the demographic data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this data project is based around the immigration data, we will use the immigration data as teh center of star schema (our fact table).\n",
    "We will be calling this table as fact_immigration:\n",
    "`\n",
    "CREATE TABLE fact_immigration\n",
    "(\n",
    "    immigration_id int not null identity(0,1) primary key,\n",
    "    cicid decimal not null,\n",
    "    i94yr decimal not null,\n",
    "    i94mon decimal not null,\n",
    "    i94cit decimal,\n",
    "    i94res decimal,\n",
    "    i94port char(3),\n",
    "    arrdate decimal,\n",
    "    i94mode decimal,\n",
    "    i94addr char(3),\n",
    "    depdate decimal,\n",
    "    i94bir decimal,\n",
    "    i94visa decimal,\n",
    "    count decimal,\n",
    "    dtadfile varchar,\n",
    "    visapost char(3),\n",
    "    occup char(3),\n",
    "    entdepa char(1),\n",
    "    entdepd char(1),\n",
    "    entdepu char(1),\n",
    "    matflag char(1),\n",
    "    biryear decimal,\n",
    "    dtaddto varchar,\n",
    "    gender char(1),\n",
    "    insnum varchar,\n",
    "    airline char(3),\n",
    "    admnum varchar, \n",
    "    fltno varchar,\n",
    "    visatype char(3)\n",
    "    );\n",
    "`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the dimension tables:\n",
    "\n",
    "dim_country\n",
    "`\n",
    "CREATE TABLE dim_country(\n",
    "    code integer not null constraint dim_country_pkey primary key,\n",
    "    name varchar not null\n",
    ")\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dim_arrival_mode\n",
    "\n",
    "`\n",
    "CREATE TABLE dim_arrival_mode(\n",
    "    code integer,\n",
    "    mode char(12)\n",
    ")`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dim_port\n",
    "\n",
    "`\n",
    "CREATE TABLE dim_port(\n",
    "    code char(3),\n",
    "    name varchar\n",
    ")`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dim_address\n",
    "\n",
    "`\n",
    "CREATE TABLE dim_address(\n",
    "    code char(2),\n",
    "    name varchar\n",
    ")`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dim_visa_type\n",
    "\n",
    "`\n",
    "CREATE TABLE dim_visa_type(\n",
    "    code integer,\n",
    "    visa_type char(8)\n",
    ")\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dim_date\n",
    "\n",
    "`\n",
    "CREATE TABLE dim_date(\n",
    "    code integer not null constraint dim_date_pkey primary key,\n",
    "    year integer not null,\n",
    "    month integer not null,\n",
    "    day integer not null,\n",
    "    day_of_week integer not null,\n",
    "    ymd_dash char(10) not null,\n",
    "    ymd_nodash char(8) not null,\n",
    "    mdy_nodash char(8) not null\n",
    ")`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dim_city\n",
    "\n",
    "`\n",
    "CREATE TABLE dim_city(\n",
    "    city varchar,\n",
    "    state varchar,\n",
    "    median_age numeric,\n",
    "    male_pop integer,\n",
    "    female_pop integer, \n",
    "    total_pop integer,\n",
    "    num_vets integer,\n",
    "    foreign_born integer,\n",
    "    avg_household_size DECIMAL,\n",
    "    state_code char(2),\n",
    "    race varchar,\n",
    "    count integer\n",
    ")\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dim_state\n",
    "\n",
    "`\n",
    "CREATE TABLE dim_state(\n",
    "    state_code char(2) constraint dim_state_pkey primary key,\n",
    "    male_pop integer,\n",
    "    female_pop integer,\n",
    "    total_pop integer,\n",
    "    foreign_born integer\n",
    ")`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. fact_immigraiton\n",
    "\n",
    "This one is by far the most complicated process since we would need to import large file sets.\n",
    "\n",
    "We need to import each of the 12 files one at a time into memory (dataframe) first before we can insert into our redshift table.  After each insert, we would need to delete the dataframe to free up memory before proceeding to the next file.  \n",
    "\n",
    "In addition, we found out the month of June actually contains extra columns, so we need to add code to clean up those unnecessary info before we can process the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. dim_arrival_mode and dim_visa_type\n",
    "\n",
    "These two tables are more of a small lookup table.  We are just going to hardcode the insert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. dim_address, dim_port, and dim_country\n",
    "\n",
    "We are going to parse the value from the file and insert the result into the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. dim_city and dim_state\n",
    "\n",
    "We are going to insert directly from the dataframe we created at exploration stage and insert those into the refshift directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are making db connection first\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dbaccess.cfg')\n",
    "connection_string = \"host={} dbname={} user={} password={} port={}\".format(*config['CLUSTER'].values())\n",
    "engine_connection_string='postgres://{}:{}@{}:{}/{}'.format(config['CLUSTER']['DB_USER'], config['CLUSTER']['DB_PASSWORD'], config['JDBC']['JDBCURL'], config['CLUSTER']['DB_PORT'], config['CLUSTER']['DB_NAME'])               \n",
    "engine = create_engine(engine_connection_string)  # needed for DataFrame.to_sql\n",
    "\n",
    "conn = psycopg2.connect(connection_string)\n",
    "cur = conn.cursor()\n",
    "conn.set_session(autocommit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here\n",
    "# We are going to clear the table if they exist first\n",
    "sql_drop_dim_visa_type = 'DROP TABLE IF EXISTS dim_visa_type;'\n",
    "cur.execute(sql_drop_dim_visa_type)\n",
    "\n",
    "sql_drop_dim_state = 'DROP TABLE IF EXISTS dim_state;'\n",
    "cur.execute(sql_drop_dim_state)\n",
    "\n",
    "sql_drop_dim_country = 'DROP TABLE IF EXISTS dim_country;'\n",
    "cur.execute(sql_drop_dim_country)\n",
    "\n",
    "sql_drop_dim_city = 'DROP TABLE IF EXISTS dim_city;'\n",
    "cur.execute(sql_drop_dim_city)\n",
    "\n",
    "sql_drop_dim_date = 'DROP TABLE IF EXISTS dim_date;'\n",
    "cur.execute(sql_drop_dim_date)\n",
    "\n",
    "sql_drop_dim_address = 'DROP TABLE IF EXISTS dim_address;'\n",
    "cur.execute(sql_drop_dim_address)\n",
    "\n",
    "sql_drop_dim_port = 'DROP TABLE IF EXISTS dim_port;'\n",
    "cur.execute(sql_drop_dim_port)\n",
    "\n",
    "sql_drop_dim_arrival_mode = 'DROP TABLE IF EXISTS dim_arrival_mode;'\n",
    "cur.execute(sql_drop_dim_arrival_mode)\n",
    "\n",
    "#We are handling the fact_immigration in a python file\n",
    "#sql_drop_fact_immigration = 'DROP TABLE IF EXISTS fact_immigration;'\n",
    "#cur.execute(sql_drop_fact_immigration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsql_create_fact_immigration = CREATE TABLE fact_immigration(\\n    immigration_id int not null identity(0,1) primary key,\\n    cicid decimal not null,\\n    i94yr decimal not null,\\n    i94mon decimal not null,\\n    i94cit decimal,\\n    i94res decimal,\\n    i94port char(3),\\n    arrdate decimal,\\n    i94mode decimal,\\n    i94addr char(3),\\n    depdate decimal,\\n    i94bir decimal,\\n    i94visa decimal,\\n    count decimal,\\n    dtadfile varchar,\\n    visapost char(3),\\n    occup char(3),\\n    entdepa char(1),\\n    entdepd char(1),\\n    entdepu char(1),\\n    matflag char(1),\\n    biryear decimal,\\n    dtaddto varchar,\\n    gender char(1),\\n    insnum varchar,\\n    airline char(3),\\n    admnum varchar, \\n    fltno varchar,\\n    visatype char(3)\\n    );\\ncur.execute(sql_create_fact_immigration)'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create all tables\n",
    "sql_create_dim_visa_type = '''CREATE TABLE dim_visa_type(\n",
    "                                code integer,\n",
    "                                visa_type char(8)\n",
    "                            )'''\n",
    "cur.execute(sql_create_dim_visa_type)\n",
    "\n",
    "sql_create_dim_state = '''CREATE TABLE dim_state(\n",
    "    state_code char(2) constraint dim_state_pkey primary key,\n",
    "    male_pop decimal,\n",
    "    female_pop decimal,\n",
    "    total_pop decimal,\n",
    "    foreign_born decimal\n",
    ")'''\n",
    "cur.execute(sql_create_dim_state)\n",
    "\n",
    "sql_create_dim_country = '''CREATE TABLE dim_country(\n",
    "    code integer not null constraint dim_country_pkey primary key,\n",
    "    name varchar not null\n",
    ")'''\n",
    "cur.execute(sql_create_dim_country)\n",
    "\n",
    "sql_create_dim_city = '''CREATE TABLE dim_city(\n",
    "    city varchar,\n",
    "    state varchar,\n",
    "    median_age numeric,\n",
    "    male_pop decimal,\n",
    "    female_pop decimal, \n",
    "    total_pop decimal,\n",
    "    num_vets integer,\n",
    "    foreign_born decimal,\n",
    "    avg_household_size DECIMAL,\n",
    "    state_code char(2),\n",
    "    race varchar,\n",
    "    count integer\n",
    ")'''\n",
    "cur.execute(sql_create_dim_city)\n",
    "\n",
    "sql_create_dim_date = '''CREATE TABLE dim_date(\n",
    "    code integer not null constraint dim_date_pkey primary key,\n",
    "    year integer not null,\n",
    "    month integer not null,\n",
    "    day integer not null,\n",
    "    day_of_week integer not null,\n",
    "    ymd_dash char(10) not null,\n",
    "    ymd_nodash char(8) not null,\n",
    "    mdy_nodash char(8) not null\n",
    ")'''\n",
    "cur.execute(sql_create_dim_date)\n",
    "\n",
    "sql_create_dim_address = '''CREATE TABLE dim_address(\n",
    "    code char(2),\n",
    "    name varchar\n",
    ")'''\n",
    "cur.execute(sql_create_dim_address)\n",
    "\n",
    "sql_create_dim_port = '''CREATE TABLE dim_port(\n",
    "    code char(3),\n",
    "    name varchar\n",
    ")'''\n",
    "cur.execute(sql_create_dim_port)\n",
    "\n",
    "sql_create_dim_arrival_mode = '''CREATE TABLE dim_arrival_mode(\n",
    "    code integer,\n",
    "    mode char(12)\n",
    ")'''\n",
    "cur.execute(sql_create_dim_arrival_mode)\n",
    "\n",
    "#creating of fact_immigration is being handled outside of the notebook\n",
    "'''\n",
    "sql_create_fact_immigration = CREATE TABLE fact_immigration(\n",
    "    immigration_id int not null identity(0,1) primary key,\n",
    "    cicid decimal not null,\n",
    "    i94yr decimal not null,\n",
    "    i94mon decimal not null,\n",
    "    i94cit decimal,\n",
    "    i94res decimal,\n",
    "    i94port char(3),\n",
    "    arrdate decimal,\n",
    "    i94mode decimal,\n",
    "    i94addr char(3),\n",
    "    depdate decimal,\n",
    "    i94bir decimal,\n",
    "    i94visa decimal,\n",
    "    count decimal,\n",
    "    dtadfile varchar,\n",
    "    visapost char(3),\n",
    "    occup char(3),\n",
    "    entdepa char(1),\n",
    "    entdepd char(1),\n",
    "    entdepu char(1),\n",
    "    matflag char(1),\n",
    "    biryear decimal,\n",
    "    dtaddto varchar,\n",
    "    gender char(1),\n",
    "    insnum varchar,\n",
    "    airline char(3),\n",
    "    admnum varchar, \n",
    "    fltno varchar,\n",
    "    visatype char(3)\n",
    "    );\n",
    "cur.execute(sql_create_fact_immigration)'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have create the table, we can start the data insert process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_insert_arrival_mode = \"\"\"INSERT INTO dim_arrival_mode(code, mode)\n",
    "SELECT 1, 'Air'\n",
    "UNION\n",
    "SELECT 2, 'Sea'\n",
    "UNION\n",
    "SELECT 3, 'Land'\n",
    "UNION\n",
    "SELECT 9, 'Not Reported'\n",
    "\n",
    "\"\"\"\n",
    "cur.execute(sql_insert_arrival_mode)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_insert_visa_type = \"\"\"INSERT INTO dim_visa_type(code, visa_type)\n",
    "SELECT 1, 'Business'\n",
    "UNION\n",
    "SELECT 2, 'Pleasure'\n",
    "UNION\n",
    "SELECT 3, 'Student'\n",
    "\n",
    "\"\"\"\n",
    "cur.execute(sql_insert_visa_type)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sql_insert_address\n",
    "with open(HEADER_FILE) as f:\n",
    "    header_files = f.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code:I94YR, description:4 digit year\n",
      "code:I94MON, description:Numeric month\n",
      "code:I94CIT & I94RES, description:This format shows all the valid and invalid codes for processing\n",
      "code:I94PORT, description:This format shows all the valid and invalid codes for processing\n",
      "code:I94MODE, description:There are missing values as well as not reported (9)\n",
      "code:I94BIR, description:Age of Respondent in Years\n",
      "code:COUNT, description:Used for summary statistics\n",
      "code:DTADFILE, description:Character Date Field - Date added to I-94 Files - CIC does not use\n",
      "code:VISAPOST, description:Department of State where where Visa was issued - CIC does not use\n",
      "code:OCCUP, description:Occupation that will be performed in U.S. - CIC does not use\n",
      "code:ENTDEPA, description:Arrival Flag - admitted or paroled into the U.S. - CIC does not use\n",
      "code:ENTDEPD, description:Departure Flag - Departed, lost I-94 or is deceased - CIC does not use\n",
      "code:ENTDEPU, description:Update Flag - Either apprehended, overstayed, adjusted to perm residence - CIC does not use\n",
      "code:MATFLAG, description:Match flag - Match of arrival and departure records\n",
      "code:BIRYEAR, description:4 digit year of birth\n",
      "code:DTADDTO, description:Character Date Field - Date to which admitted to U.S. (allowed to stay until) - CIC does not use\n",
      "code:GENDER, description:Non-immigrant sex\n",
      "code:INSNUM, description:INS number\n",
      "code:AIRLINE, description:Airline used to arrive in U.S.\n",
      "code:ADMNUM, description:Admission Number\n",
      "code:FLTNO, description:Flight number of Airline used to arrive in U.S.\n",
      "code:VISATYPE, description:Class of admission legally admitting the non-immigrant to temporarily stay in U.S.\n"
     ]
    }
   ],
   "source": [
    "comments = [line for line in header_files if line.startswith('/*') and line.endswith('*/\\n')]\n",
    "comment_pattern = re.compile(r'^/\\*\\s+(?P<code>.+?)\\s+-\\s+(?P<description>.+)\\s+\\*/$')\n",
    "matches = [comment_pattern.match(cl) for cl in comments]\n",
    "\n",
    "if not all(m is not None for m in matches):\n",
    "    for i, m in enumerate(matches):\n",
    "        if m is None:\n",
    "            print(i)\n",
    "\n",
    "\n",
    "matches = [comment_pattern.match(cl) for cl in comments]\n",
    "if not all(m is not None for m in matches):\n",
    "    for i, m in enumerate(matches):\n",
    "        if m is None:\n",
    "            print(i)\n",
    "for m in matches:\n",
    "    print('code:{}, description:{}'.format(m.group(\"code\"), m.group('description')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time to parse out address\n",
    "address_lines = header_files[981:1036]\n",
    "\n",
    "pattern = re.compile(r\"^\\s*'(?P<code>..)'\\s*=\\s*'(?P<name>.+)'.*$\")\n",
    "matches = [pattern.match(line) for line in address_lines]\n",
    "\n",
    "address_codes = {match.group('code'): match.group('name') for match in matches}\n",
    "assert len(address_codes) == len(address_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_insert_address_template = 'INSERT INTO dim_address (code, name) VALUES (%s, %s);'\n",
    "\n",
    "for item in sorted(address_codes.items()):\n",
    "    cur.execute(sql_insert_address_template, item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time to parse out port\n",
    "port_lines = header_files[302:962]\n",
    "pattern = re.compile(r\"^\\s*'(?P<code>...?)'\\s*=\\s*'(?P<name>.+)'.*$\")\n",
    "matches = [pattern.match(line) for line in port_lines]\n",
    "port_codes = {match.group('code'): match.group('name').strip() for match in matches}\n",
    "assert len(port_codes) == len(port_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_insert_port_template = 'INSERT INTO dim_port (code, name) VALUES (%s, %s);'\n",
    "\n",
    "for item in sorted(port_codes.items()):\n",
    "    cur.execute(sql_insert_port_template, item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time to parse out countries\n",
    "country_lines = header_files[9:298]\n",
    "pattern = re.compile(r\"^\\s*(?P<code>\\d+)\\s*=\\s*'(?P<country>.+)'.*$\")\n",
    "matches = [pattern.match(line) for line in country_lines]\n",
    "country_codes = {int(match.group('code')): match.group('country') for match in matches}\n",
    "assert len(country_lines) == len(country_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_insert_country_template = 'INSERT INTO dim_country (code, name) VALUES (%s, %s) '\n",
    "\n",
    "\n",
    "for item in country_codes.items():\n",
    "    cur.execute(sql_insert_country_template, item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dim_date\n",
    "\n",
    "Populating dim_date is different from other tables.  Since we have birth yeear from 1990 and the data was released on 2016, we will populate every day from 1/1/1900 to 12/31/2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_insert_date_template = 'INSERT INTO dim_date(code, year, month, day, day_of_week, ymd_dash, ymd_nodash, mdy_nodash) values (%s, %s, %s, %s, %s, %s, %s, %s);'\n",
    "\n",
    "\n",
    "dt = datetime(2016,1,1)\n",
    "end_dt = datetime(2016, 12, 31)\n",
    "one_day = timedelta(days=1)\n",
    "code = 20454\n",
    "\n",
    "while dt <= end_dt:\n",
    "    cur.execute(sql_insert_date_template, \n",
    "               [code, dt.year, dt.month, dt.day, dt.weekday(), dt.strftime('%Y-%m-%d'),\n",
    "                dt.strftime('%Y%m%d'), dt.strftime('%d%m%Y')]\n",
    "               )\n",
    "    dt = dt + one_day\n",
    "    code += 1\n",
    "    \n",
    "\n",
    "dt = datetime(2015, 12, 31)\n",
    "end_dt = datetime(1900, 1, 1)\n",
    "code = 20453\n",
    "\n",
    "while dt >= end_dt:\n",
    "    cur.execute(sql_insert_date_template, \n",
    "               [code, dt.year, dt.month, dt.day, dt.weekday(), dt.strftime('%Y-%m-%d'),\n",
    "                dt.strftime('%Y%m%d'), dt.strftime('%d%m%Y')]\n",
    "               )\n",
    "    dt = dt - one_day\n",
    "    code -=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inserting dim_city\n",
    "sql_insert_city_template = '''INSERT INTO dim_city (city, state, median_age, male_pop, female_pop, total_pop\n",
    ", num_vets, foreign_born, avg_household_size, state_code, race, count)\n",
    "VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s);'''\n",
    "\n",
    "# execute queries\n",
    "for _, row in city_df.iterrows():\n",
    "    cur.execute(sql_insert_city_template, [v if pd.notna(v) else None for v in row])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert dim_state\n",
    "sql_insert_state_template = '''INSERT INTO dim_state\n",
    "(state_code, male_pop, female_pop, total_pop, foreign_born)\n",
    "VALUES (%s, %s, %s, %s, %s)'''\n",
    "\n",
    "# execute queries\n",
    "for _, row in state_df.iterrows():\n",
    "    cur.execute(sql_insert_state_template, row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling fact_immigration\n",
    "\n",
    "Because fact_immigration has huge amount of data, we want to handle the insert outside of the jupyter notebook as we do not wish to crash our internet browser.\n",
    "\n",
    "I will be running load_fact_immgration_data.py in my local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approach that I used in the load_immigraiton_data.py is fairly straight forward.  Just read the sas data into dataframe, push the dataframe through Amazon's S3 through CSV file format.  Then we utilized the COPY command from RedShift.  This approach cuts the import time down dramatically.\n",
    "\n",
    "python load_immigration_data.py\n",
    "\n",
    "Necessary libraries are pandas, pscopg2, tqdm. These can be installed via\n",
    "\n",
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first data quality check is actually just to look at how many rows we have by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>i94mon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>500000</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>500000</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>500000</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>500000</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>500000</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>500000</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>500000</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     count  i94mon\n",
       "0   500000     1.0\n",
       "1   500000     2.0\n",
       "2   500000     3.0\n",
       "3   500000     4.0\n",
       "4   500000     5.0\n",
       "5   500000     6.0\n",
       "6   500000     7.0\n",
       "7   500000     8.0\n",
       "8   500000     9.0\n",
       "9   500000    10.0\n",
       "10  500000    11.0\n",
       "11  500000    12.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform quality checks here\n",
    "#using the following sql statement:\n",
    "sql_data_quality_check_template = '''select count(distinct immigration_id), i94mon\n",
    "from fact_immigration\n",
    "group by i94mon\n",
    "order by i94mon;'''\n",
    "dq_check_df = pd.read_sql_query(sql_data_quality_check_template, engine)\n",
    "dq_check_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second data quality check is to make sure we only have data from year 2016. \n",
    "\n",
    "As we can see from the result, we do not have any data outside of 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total\n",
       "0      0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_data_quality_check_template = 'select count(1) as Total from fact_immigration where i94yr is null or i94yr <> 2016;'\n",
    "dq_check_df = pd.read_sql_query(sql_data_quality_check_template, engine)\n",
    "dq_check_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third data quality check is to examin into the cicid column.  From the first glance, this field looks like the primary key for the immigration data.  Let's explore it and see if that's the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32175.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34883.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33202.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34926.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34934.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35286.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35041.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>35765.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>35829.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36163.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>36934.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>36202.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>37116.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>37471.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>37346.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>37491.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>37384.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>37861.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>40784.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>42076.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>41799.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>42824.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>42974.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>42850.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>43553.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>43556.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>43591.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>43558.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>51542.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>43587.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114853</th>\n",
       "      <td>1124230.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114854</th>\n",
       "      <td>1124252.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114855</th>\n",
       "      <td>1124275.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114856</th>\n",
       "      <td>1124282.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114857</th>\n",
       "      <td>1124312.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114858</th>\n",
       "      <td>1124384.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114859</th>\n",
       "      <td>1124390.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114860</th>\n",
       "      <td>1124398.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114861</th>\n",
       "      <td>1124400.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114862</th>\n",
       "      <td>1124409.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114863</th>\n",
       "      <td>1124419.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114864</th>\n",
       "      <td>1124432.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114865</th>\n",
       "      <td>1124463.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114866</th>\n",
       "      <td>1124467.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114867</th>\n",
       "      <td>1124535.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114868</th>\n",
       "      <td>1124553.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114869</th>\n",
       "      <td>1124557.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114870</th>\n",
       "      <td>1124563.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114871</th>\n",
       "      <td>1124586.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114872</th>\n",
       "      <td>1124589.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114873</th>\n",
       "      <td>1124594.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114874</th>\n",
       "      <td>1124596.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114875</th>\n",
       "      <td>1124600.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114876</th>\n",
       "      <td>1124622.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114877</th>\n",
       "      <td>1124630.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114878</th>\n",
       "      <td>1124721.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114879</th>\n",
       "      <td>1124738.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114880</th>\n",
       "      <td>1124743.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114881</th>\n",
       "      <td>1124876.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114882</th>\n",
       "      <td>1124913.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1114883 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             cicid  count\n",
       "0          32175.0     12\n",
       "1          34883.0     12\n",
       "2          33202.0     12\n",
       "3          34926.0     12\n",
       "4          34934.0     12\n",
       "5          35286.0     12\n",
       "6          35041.0     12\n",
       "7          35765.0     12\n",
       "8          35829.0     12\n",
       "9          36163.0     12\n",
       "10         36934.0     12\n",
       "11         36202.0     12\n",
       "12         37116.0     12\n",
       "13         37471.0     12\n",
       "14         37346.0     12\n",
       "15         37491.0     12\n",
       "16         37384.0     12\n",
       "17         37861.0     12\n",
       "18         40784.0     12\n",
       "19         42076.0     12\n",
       "20         41799.0     12\n",
       "21         42824.0     12\n",
       "22         42974.0     12\n",
       "23         42850.0     12\n",
       "24         43553.0     12\n",
       "25         43556.0     12\n",
       "26         43591.0     12\n",
       "27         43558.0     12\n",
       "28         51542.0     12\n",
       "29         43587.0     12\n",
       "...            ...    ...\n",
       "1114853  1124230.0      1\n",
       "1114854  1124252.0      1\n",
       "1114855  1124275.0      1\n",
       "1114856  1124282.0      1\n",
       "1114857  1124312.0      1\n",
       "1114858  1124384.0      1\n",
       "1114859  1124390.0      1\n",
       "1114860  1124398.0      1\n",
       "1114861  1124400.0      1\n",
       "1114862  1124409.0      1\n",
       "1114863  1124419.0      1\n",
       "1114864  1124432.0      1\n",
       "1114865  1124463.0      1\n",
       "1114866  1124467.0      1\n",
       "1114867  1124535.0      1\n",
       "1114868  1124553.0      1\n",
       "1114869  1124557.0      1\n",
       "1114870  1124563.0      1\n",
       "1114871  1124586.0      1\n",
       "1114872  1124589.0      1\n",
       "1114873  1124594.0      1\n",
       "1114874  1124596.0      1\n",
       "1114875  1124600.0      1\n",
       "1114876  1124622.0      1\n",
       "1114877  1124630.0      1\n",
       "1114878  1124721.0      1\n",
       "1114879  1124738.0      1\n",
       "1114880  1124743.0      1\n",
       "1114881  1124876.0      1\n",
       "1114882  1124913.0      1\n",
       "\n",
       "[1114883 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_data_quality_check_template = 'select cicid, count(cicid) from fact_immigration group by cicid order by count desc;'\n",
    "dq_check_df = pd.read_sql_query(sql_data_quality_check_template, engine)\n",
    "dq_check_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there are few cicid's that appear multiple times.  Let's examin some of those rows see if we can find out more.\n",
    "\n",
    "After inspecting the samples (see below), we know that these are not duplicate records and we made a good decision for not using cicid as our primary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>immigration_id</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>...</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>421527</td>\n",
       "      <td>395680.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>FTL</td>\n",
       "      <td>20455.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>US</td>\n",
       "      <td>20463.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>PTS</td>\n",
       "      <td></td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td>M</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>M</td>\n",
       "      <td></td>\n",
       "      <td>BW</td>\n",
       "      <td>84246707530.0</td>\n",
       "      <td>00480</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1360193</td>\n",
       "      <td>395680.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>687.0</td>\n",
       "      <td>687.0</td>\n",
       "      <td>MIA</td>\n",
       "      <td>20486.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CO</td>\n",
       "      <td>20498.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>BNS</td>\n",
       "      <td></td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td>M</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>08012016</td>\n",
       "      <td>M</td>\n",
       "      <td></td>\n",
       "      <td>AA</td>\n",
       "      <td>87088113930.0</td>\n",
       "      <td>00900</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>426916</td>\n",
       "      <td>395680.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>690.0</td>\n",
       "      <td>690.0</td>\n",
       "      <td>HOU</td>\n",
       "      <td>20607.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20619.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td>M</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>08302016</td>\n",
       "      <td>F</td>\n",
       "      <td></td>\n",
       "      <td>UA</td>\n",
       "      <td>61347834233.0</td>\n",
       "      <td>00846</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1402578</td>\n",
       "      <td>395680.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20516.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>LA</td>\n",
       "      <td>20521.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>05312016</td>\n",
       "      <td>M</td>\n",
       "      <td></td>\n",
       "      <td>VA</td>\n",
       "      <td>53739138933.0</td>\n",
       "      <td>00001</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2363804</td>\n",
       "      <td>395680.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>SNA</td>\n",
       "      <td>20546.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>20577.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>SNJ</td>\n",
       "      <td></td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td>M</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>10012016</td>\n",
       "      <td>M</td>\n",
       "      <td></td>\n",
       "      <td>4O</td>\n",
       "      <td>92556376030.0</td>\n",
       "      <td>02950</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3457726</td>\n",
       "      <td>395680.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20637.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20650.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>ABD</td>\n",
       "      <td></td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td>M</td>\n",
       "      <td>1966.0</td>\n",
       "      <td>01012017</td>\n",
       "      <td>M</td>\n",
       "      <td></td>\n",
       "      <td>EK</td>\n",
       "      <td>15670443340.0</td>\n",
       "      <td>00201</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2409143</td>\n",
       "      <td>395680.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>691.0</td>\n",
       "      <td>691.0</td>\n",
       "      <td>DAL</td>\n",
       "      <td>20576.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>20581.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>BGT</td>\n",
       "      <td></td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td>M</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>11012016</td>\n",
       "      <td>M</td>\n",
       "      <td></td>\n",
       "      <td>AV</td>\n",
       "      <td>95166856730.0</td>\n",
       "      <td>00440</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5471178</td>\n",
       "      <td>395680.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>MIA</td>\n",
       "      <td>20729.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20735.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>RDJ</td>\n",
       "      <td></td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td>M</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>04012017</td>\n",
       "      <td>F</td>\n",
       "      <td></td>\n",
       "      <td>AA</td>\n",
       "      <td>19371516140.0</td>\n",
       "      <td>00234</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4464564</td>\n",
       "      <td>395680.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>MIA</td>\n",
       "      <td>20668.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WI</td>\n",
       "      <td>20692.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>02012017</td>\n",
       "      <td>F</td>\n",
       "      <td>182766</td>\n",
       "      <td>AA</td>\n",
       "      <td>4637606585.0</td>\n",
       "      <td>1030</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6433302</td>\n",
       "      <td>395680.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>SFR</td>\n",
       "      <td>20761.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20823.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>MDR</td>\n",
       "      <td></td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td>M</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>05022017</td>\n",
       "      <td>F</td>\n",
       "      <td>25442</td>\n",
       "      <td>BA</td>\n",
       "      <td>13013813185.0</td>\n",
       "      <td>287</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3423899</td>\n",
       "      <td>395680.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20699.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20703.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>11302016</td>\n",
       "      <td>M</td>\n",
       "      <td></td>\n",
       "      <td>HA</td>\n",
       "      <td>8561773085.0</td>\n",
       "      <td>822</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7380158</td>\n",
       "      <td>395680.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>NEW</td>\n",
       "      <td>20790.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NJ</td>\n",
       "      <td>20801.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td>M</td>\n",
       "      <td>1948.0</td>\n",
       "      <td>03012017</td>\n",
       "      <td>F</td>\n",
       "      <td></td>\n",
       "      <td>EI</td>\n",
       "      <td>15416156385.0</td>\n",
       "      <td>101</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    immigration_id     cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  \\\n",
       "0           421527  395680.0  2016.0     1.0   516.0   516.0     FTL  20455.0   \n",
       "1          1360193  395680.0  2016.0     2.0   687.0   687.0     MIA  20486.0   \n",
       "2           426916  395680.0  2016.0     6.0   690.0   690.0     HOU  20607.0   \n",
       "3          1402578  395680.0  2016.0     3.0   438.0   438.0     LOS  20516.0   \n",
       "4          2363804  395680.0  2016.0     4.0   582.0   582.0     SNA  20546.0   \n",
       "5          3457726  395680.0  2016.0     7.0   213.0   296.0     NYC  20637.0   \n",
       "6          2409143  395680.0  2016.0     5.0   691.0   691.0     DAL  20576.0   \n",
       "7          5471178  395680.0  2016.0    10.0   689.0   689.0     MIA  20729.0   \n",
       "8          4464564  395680.0  2016.0     8.0   528.0   528.0     MIA  20668.0   \n",
       "9          6433302  395680.0  2016.0    11.0   213.0   213.0     SFR  20761.0   \n",
       "10         3423899  395680.0  2016.0     9.0   209.0   209.0     HHW  20699.0   \n",
       "11         7380158  395680.0  2016.0    12.0   116.0   116.0     NEW  20790.0   \n",
       "\n",
       "    i94mode i94addr  depdate  i94bir  i94visa  count   ...    visapost occup  \\\n",
       "0       1.0     US   20463.0    35.0      2.0    1.0   ...         PTS         \n",
       "1       1.0     CO   20498.0    47.0      2.0    1.0   ...         BNS         \n",
       "2       1.0     FL   20619.0    11.0      2.0    1.0   ...                     \n",
       "3       1.0     LA   20521.0    29.0      2.0    1.0   ...                     \n",
       "4       1.0     TX   20577.0    45.0      1.0    1.0   ...         SNJ         \n",
       "5       1.0     NY   20650.0    50.0      2.0    1.0   ...         ABD         \n",
       "6       1.0     TX   20581.0    39.0      2.0    1.0   ...         BGT         \n",
       "7       1.0     FL   20735.0    27.0      2.0    1.0   ...         RDJ         \n",
       "8       1.0     WI   20692.0    25.0      2.0    1.0   ...                     \n",
       "9       1.0     CA   20823.0    64.0      2.0    1.0   ...         MDR         \n",
       "10      1.0     HI   20703.0    25.0      2.0    1.0   ...                     \n",
       "11      1.0     NJ   20801.0    68.0      2.0    1.0   ...                     \n",
       "\n",
       "   entdepa entdepd entdepu matflag biryear   dtaddto gender  insnum airline  \\\n",
       "0        G       O               M  1981.0  07012016      M             BW    \n",
       "1        G       O               M  1969.0  08012016      M             AA    \n",
       "2        G       O               M  2005.0  08302016      F             UA    \n",
       "3        G       O               M  1987.0  05312016      M             VA    \n",
       "4        G       O               M  1971.0  10012016      M             4O    \n",
       "5        G       O               M  1966.0  01012017      M             EK    \n",
       "6        G       O               M  1977.0  11012016      M             AV    \n",
       "7        G       O               M  1989.0  04012017      F             AA    \n",
       "8        G       O               M  1991.0  02012017      F  182766     AA    \n",
       "9        G       O               M  1952.0  05022017      F   25442     BA    \n",
       "10       G       O               M  1991.0  11302016      M             HA    \n",
       "11       G       O               M  1948.0  03012017      F             EI    \n",
       "\n",
       "           admnum  fltno visatype  \n",
       "0   84246707530.0  00480      B2   \n",
       "1   87088113930.0  00900      B2   \n",
       "2   61347834233.0  00846      WT   \n",
       "3   53739138933.0  00001      WT   \n",
       "4   92556376030.0  02950      B1   \n",
       "5   15670443340.0  00201      B2   \n",
       "6   95166856730.0  00440      B2   \n",
       "7   19371516140.0  00234      B2   \n",
       "8    4637606585.0   1030      B2   \n",
       "9   13013813185.0    287      B2   \n",
       "10   8561773085.0    822      WT   \n",
       "11  15416156385.0    101      WT   \n",
       "\n",
       "[12 rows x 29 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_data_quality_check_template = '''select * from fact_immigration\n",
    "where cicid in (5454856, 3334634, 4087143, 395680)\n",
    "order by cicid;'''\n",
    "dq_check_df = pd.read_sql_query(sql_data_quality_check_template, engine)\n",
    "dq_check_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we found out in data exploration stage, there are some of the birth year we need to fix/exclude.  So we will run the below sql statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_data_quality_fix = '''UPDATE fact_immigration\n",
    "SET i94bir = NULL\n",
    "WHERE i94bir < 0 or i94bir > 120;'''\n",
    "\n",
    "cur.execute(sql_data_quality_fix)\n",
    "sql_data_quality_fix = '''UPDATE fact_immigration\n",
    "SET biryear = NULL\n",
    "WHERE biryear < 1900 or biryear > 2016;'''\n",
    "\n",
    "cur.execute(sql_data_quality_fix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### dim_visa_type\n",
    "This table contains the type visa immigration uses:\n",
    "\n",
    "- code: 1, 2, 3\n",
    "- visa_tyope: Business, Pleasure, or Student, respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### dim_state\n",
    "This table contains the aggregated statistics from dim_city by state\n",
    "\n",
    "- state_code: two-letter code for state\n",
    "- male_pop: number of men in the state\n",
    "- female_pop: number of women in the state\n",
    "- total_pop: number of people in the state\n",
    "- foreign_born: number of foreign-born people in the state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### dim_country\n",
    "This table stores the country name and code from our immigration data\n",
    "\n",
    "- code: a numbered code\n",
    "- name: usually a name of a country. There are many that start with INVALID: as well as several different No Country Code([code]) values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### dim_city\n",
    "This table stores the statistics on cities in US\n",
    "\n",
    "- city: city's name\n",
    "- state: state city is in\n",
    "- median_age: median age of city\n",
    "- male_pop: number of men in the city\n",
    "- female_pop: number of women in the city\n",
    "- total_pop: number of people in the city\n",
    "- num_vets: number of veterans in the city\n",
    "- foreign_born: number of foreign-born people in the city\n",
    "- avg_household_size: average household size\n",
    "- state_code: two-letter code for state\n",
    "- race: White, Hispanic or Latino, Asian, Black or African-American, or American Indian and Alaska Native\n",
    "- count: number of people of that race in the city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### dim_date\n",
    "This table stores the dates in different formats\n",
    "\n",
    "- code: the CIC code for date where 20454 is 1/1/2016\n",
    "- year: four-digit year\n",
    "- month: month; 1-12\n",
    "- day: day; 1-31\n",
    "- day_of_week: 0 for Monday, 1 for Tuesday, ..., 7 for Sunday\n",
    "- ymd_dash: date formatted as YYYY-MM-DD\n",
    "- ymd_nodash: date formatted as YYYYMMDD\n",
    "- mdy_noash: date formatted as MMDDYYYY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### dim_address\n",
    "This table stores the list of the states (usually) where immigrants list their address\n",
    "\n",
    "- code: mostly two-letter codes for states. There's DC, GU (Guam), and 99 (All Other Codes) as well\n",
    "- name: name of state, region, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### dim_port\n",
    "This table stores the list of the ports from how the immigrants arrived\n",
    "\n",
    "- code: a short code\n",
    "- name: the name of the port; there are some No PORT Code ([code]) values too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### dim_arrival_mode\n",
    "This table stores the methopd in how those immigrants arrived. \n",
    "\n",
    "- code: 1, 2, 3, or 9\n",
    "- mode: Air, Sea, Land, or Not reported, respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fact_immigration\n",
    "This table is the fact table for our data capstone project\n",
    "\n",
    "- immigration_id: primary key\n",
    "- cicid: unique key within a month\n",
    "- i94yr: 4 digit year, always 2016\n",
    "- i94mon: numeric month, 1-12\n",
    "- i94cit: immigrant's country of citizenship; foreign key to dim_country\n",
    "- i94res: immigrant's country of residence outside US; foreign key to dim_country\n",
    "- i94port: port of entry; foreign key to dim_port\n",
    "- arrdate: arrival date of immigrant where 20454 == 1/1/2016\n",
    "- i94mode: mode of arrival; foreign key to dim_arrival_mode\n",
    "- i94addr: address (usually state) of immigrant in US; foreign key to dim_address\n",
    "- depdate: departure date of immigrant where 20454 == 1/1/2016\n",
    "- i94bir: immigrant's age in years\n",
    "- i94visa: foreign key to dim_visa_type\n",
    "- count: used for summary statistics; always 1 (for easy adding)\n",
    "- dtadfile: dates in the format YYYYMMDD\n",
    "- visapost: three-letter codes corresponding to where visa was issued\n",
    "- occup: occupation in US of immigration. Mostly STU for student, also many OTH for other\n",
    "- entdepa: one-letter arrival code\n",
    "- entdepd: one-letter departure code\n",
    "- entdepu: one-letter update code\n",
    "- matflag: M if the arrival and departure records match\n",
    "- biryear: four-digit year of birth\n",
    "- dtaddto: MMDDYYYY date field for when the immigrant is admitted until\n",
    "- gender: mostly M and F, but some X and U as well\n",
    "- insnum: Immigration and Naturalization Services number; many re-used\n",
    "- airline: Airline of entry for immigrant\n",
    "- admnum: admission number; many re-used, but not as much as insnum\n",
    "- fltno: flight number of immigrant\n",
    "- visatype: short visa codes like WT, B2, WB, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "##### * Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "\n",
    "Tools and technologies\n",
    "\n",
    "For this project, I have decided to choose Python because it has a lot of useful libraries available to get the job done.  As an example, we use two different sql libraries so we can easily insert data into our RedShift datawarehouse (either with individual statement or from dataframe directly).\n",
    "\n",
    "And by exploring data using Jupyter Notebook, we can examine data interactily.  \n",
    "\n",
    "Also, python gives us an option to execute code via the console so we can be more process efficient when importing the large immigration files.\n",
    "\n",
    "We are very lucky that the immigration data set is fairly clean and we do not need to spend a lot of time to clean or transform those data.\n",
    "\n",
    "The only thing I changed is to replace NaN value for decimal into 0 and empty string for other NaN data.\n",
    "\n",
    "We decided to use RedShift as our main database backend because we can easily scale up when we need to look at more data (the beauty of the cloud)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### * Propose how often the data should be updated and why.\n",
    "\n",
    "We should be importing the immigration data on monthly basis as we receive new data.  Due to the current unstable US administration, I am curious how that affect the movement of immigration if we can tie to the change upon activation of new immigration law.  \n",
    "\n",
    "And as we import more immigration data, we will need to update the remaining dimension tables to cover the changes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### * Write a description of how you would approach the problem differently under the following scenarios:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### * The data was increased by 100x.\n",
    "\n",
    "If the data increase by 100x, we will want to utilize AirFlow as we can schedule and monitor the importing progress better.  Jupyter notebook as it's strength and weakness.  Process large amount of data is definitely something you don't want to do with the notebook.  We might also want to partition the fact table by date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "\n",
    "We can use Airflow and utilize it's SLA feature to monitor and make sure data arrives according to the requirement.,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### * The database needed to be accessed by 100+ people.\n",
    "\n",
    "This will not be a problem since we currently putting data into the RedShift already.  We can easily scale up the process to support 100+ people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
