{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLEASE RUN THE FOLLOWING CODE FOR PRE-PROCESSING THE FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "from sql_queries import *\n",
    "from refresh_database import drop_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refresh all the tables in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refresh completed!!!\n"
     ]
    }
   ],
   "source": [
    "!python refresh_database.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/workspace\n"
     ]
    }
   ],
   "source": [
    "# checking your current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    #print(file_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    " # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "# uncomment the code below if you would like to get total number of rows \n",
    "#print(len(full_data_rows_list))\n",
    "# uncomment the code below if you would like to check to see what the list of event data rows will look like\n",
    "#print(full_data_rows_list)\n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Complete the Apache Cassandra coding portion of your project. \n",
    "\n",
    "## Now you are ready to work with the CSV file titled <font color=red>event_datafile_new.csv</font>, located within the Workspace directory.  The event_datafile_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin writing your Apache Cassandra code in the cells below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making connecto to our cassandra db\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster()\n",
    "\n",
    "# To establish connection and begin executing queries, need a session\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f089041ae80>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create keyspace sparkifydb if it does not exist\n",
    "\n",
    "session.execute(\"\"\"\n",
    "        CREATE KEYSPACE IF NOT EXISTS sparkifydb\n",
    "        WITH REPLICATION =\n",
    "        { 'class' : 'SimpleStrategy', 'replication_factor': 1}\"\"\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set KEYSPACE to the keyspace to our sparkifydb\n",
    "session.set_keyspace('sparkifydb')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we need to create tables to run the following queries. Remember, with Apache Cassandra you model the database tables on the queries you want to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create queries to ask the following three questions of the data\n",
    "\n",
    "### 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "\n",
    "### 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "    \n",
    "\n",
    "### 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query #1 : \n",
    "### Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "By looking at query #1, we know our customer sparkify is trying to find out individual song's information giving a sessionId and itemInSession value.  For this reason, we are going to use sessionId and itemInSession as our primary key.  \n",
    "\n",
    "Once we have our primary key determined, we need to only include the asking columns into our table.  \n",
    "\n",
    "So our table for query #1 looks like the following\n",
    "\n",
    "- sessionId int\n",
    "- itemInSession int\n",
    "- artist text\n",
    "- song text\n",
    "- song_length decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    SELECT artist, song, song_length FROM music_history_by_sessionId_itemInSession WHERE sessionId=338 AND itemInSession=4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sample query giving 338 as sessionId and 4 as itemInSession\n",
    "print(select_by_sessionId_itemInSession % (338, 4))\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# open up the file and parse the data and insert into table line by line\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = insert_music_history_sessionId_itemInSession\n",
    "        session.execute(query, (int(line[8]), int(line[3]), line[0], line[9], float(line[5])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do a SELECT to verify that the data have been inserted into each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    SELECT artist, song, song_length FROM music_history_by_sessionId_itemInSession WHERE sessionId=589 AND itemInSession=10\n",
      "\n",
      "In Flames Like you better dead 202.84036\n"
     ]
    }
   ],
   "source": [
    "#We are using select statement validate the data we inserted into the table\n",
    "query = select_by_sessionId_itemInSession % (589, 10)\n",
    "print(query)\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "for row in rows:\n",
    "    print (row.artist, row.song, row.song_length)\n",
    "del rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query #2 : \n",
    "### Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "\n",
    "By looking at query #2, we know our customer sparkify is trying to find out our user's perference of songs giving a session.  Therefore, our primary key would be a composite key including userId and sessionId.  And since we need to sort by itemInSession, we will add that as our cluster key.  \n",
    "\n",
    "Once we have our primary key and clustering column determined, we need to only include the asking columns into our table.  \n",
    "\n",
    "So our table for query #2 looks like the following\n",
    "\n",
    "- userId int\n",
    "- sessionId int\n",
    "- artist text\n",
    "- song text\n",
    "- firstname text\n",
    "- lastname text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    SELECT artist, song, firstName, lastName FROM music_history_by_userId_session_d WHERE userId=10 AND sessionId=182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sample query giving 10 as userId and 182 as sessionId\n",
    "print(select_by_userId_sessionId % (10, 182))\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open up the file and parse the data and insert into table line by line\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:        \n",
    "        query = insert_music_history_userId_sessionId\n",
    "        session.execute(query, (int(line[10]), int(line[8]), int(line[3]), line[0], line[9], line[1], line[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    SELECT artist, song, firstName, lastName FROM music_history_by_userId_session_d WHERE userId=29 AND sessionId=589\n",
      "\n",
      "Lil Jon / The East Side Boyz / DJ Flexx Aww Skeet Skeet Jacqueline Lynch\n",
      "Enya The Sun In The Stream Jacqueline Lynch\n",
      "Furthermore We Need To Talk (She And I Album Version) Jacqueline Lynch\n",
      "Kid Cudi / MGMT / Ratatat Pursuit Of Happiness (nightmare) Jacqueline Lynch\n",
      "Crosby_ Stills & Nash Haven't We Lost Enough?  (LP Version) Jacqueline Lynch\n",
      "Passion Pit Sleepyhead Jacqueline Lynch\n",
      "Keith Sweat Merry Go Round (Remastered Single Version) Jacqueline Lynch\n",
      "In Flames Like you better dead Jacqueline Lynch\n",
      "The All-American Rejects Too Far Gone Jacqueline Lynch\n",
      "Sick Puppies Don't Walk Away Jacqueline Lynch\n",
      "Rapsusklei Nube Inerte (con Aniki) Jacqueline Lynch\n",
      "Jonezetta Untitled Jacqueline Lynch\n",
      "Cut Copy A Dream Jacqueline Lynch\n",
      "BeyoncÃÂ© Halo Jacqueline Lynch\n",
      "Easy Star All-Stars Getting Better (feat. The Mighty Diamonds) Jacqueline Lynch\n",
      "Blue Man Group Sing Along [Featuring Dave Matthews] Jacqueline Lynch\n",
      "Carpark North Run Jacqueline Lynch\n",
      "The Fleetwoods Come Softly To Me Jacqueline Lynch\n",
      "Radiohead Let Down Jacqueline Lynch\n",
      "Gorillaz Demon Days Jacqueline Lynch\n",
      "Reginald Dixon Eton Boating Song/Wyoming Lullaby/The Wiffenpoof Song (Baa Baa Baa) (Medley) Jacqueline Lynch\n",
      "Gorillaz Pirate Jet Jacqueline Lynch\n",
      "OceanLab Clear Blue Water Jacqueline Lynch\n",
      "Macy Gray Oh Yeah Jacqueline Lynch\n",
      "Tavares Don't Take Away The Music Jacqueline Lynch\n",
      "Meet Me In St Louis I've Got Knives In My Eyes I'm Going Home Sick Jacqueline Lynch\n",
      "Syd Barrett Effervescing Elephant Jacqueline Lynch\n",
      "Cat Stevens If You Want To Sing Out_ Sing Out Jacqueline Lynch\n",
      "Spoon Who Makes Your Money Jacqueline Lynch\n",
      "The Dodos Fools Jacqueline Lynch\n",
      "Cartola Tive Sim Jacqueline Lynch\n",
      "Supertramp It's Raining Again Jacqueline Lynch\n",
      "The Ruts West One (Shine On Me) Jacqueline Lynch\n",
      "Marisa Monte Abololo Jacqueline Lynch\n",
      "Smile Empty Soul Bottom of a Bottle (Explicit Album Version) Jacqueline Lynch\n",
      "M83 Unrecorded Jacqueline Lynch\n",
      "Beats Antique Roustabout (Bassnectar REMIX) Jacqueline Lynch\n",
      "Why? The Vowels Pt. 2 Jacqueline Lynch\n",
      "Chris Clark From Head To Toe Jacqueline Lynch\n",
      "The Concretes On The Radio (Edit) Jacqueline Lynch\n",
      "BeyoncÃÂ© Halo Jacqueline Lynch\n",
      "Enya Only Time (Original Version) Jacqueline Lynch\n",
      "CÃÂ©line Dion Ne me plaignez pas Jacqueline Lynch\n",
      "Rise Against Audience Of One Jacqueline Lynch\n",
      "Kaiser Chiefs Ruby Jacqueline Lynch\n",
      "Jag Panzer Reign Of The Tyrants Jacqueline Lynch\n",
      "My Chemical Romance The Ghost Of You (Album Version) Jacqueline Lynch\n",
      "Zeromancer Cupola Jacqueline Lynch\n",
      "The Cardigans Losers Jacqueline Lynch\n",
      "Future Rock Gears Jacqueline Lynch\n",
      "Lady GaGa Alejandro Jacqueline Lynch\n",
      "Keyshia Cole Superstar Jacqueline Lynch\n",
      "Big Star When My Baby's Beside Me Jacqueline Lynch\n",
      "Harmonia Sehr kosmisch Jacqueline Lynch\n",
      "Jermaine Jackson I Need You Jacqueline Lynch\n",
      "The Sons Of the Pioneers Cool Water Jacqueline Lynch\n",
      "TiÃÂ«sto In The Dark (ft. Christian Burns) Jacqueline Lynch\n",
      "U2 Window In The Skies Jacqueline Lynch\n",
      "Kanye West / Nas / Really Doe We Major Jacqueline Lynch\n",
      "Radney Foster Sweet And Wild Jacqueline Lynch\n",
      "Binary Star Solar Powered Jacqueline Lynch\n",
      "Eminem The Real Slim Shady Jacqueline Lynch\n",
      "Sick Puppies What Are You Looking For Jacqueline Lynch\n",
      "OneRepublic Secrets Jacqueline Lynch\n",
      "Say Anything Wow_ I Can Get Sexual Too Jacqueline Lynch\n",
      "Nine Inch Nails A Warm Place Jacqueline Lynch\n",
      "Bebe El Golpe Jacqueline Lynch\n",
      "Pennywise Waste of Time Jacqueline Lynch\n",
      "Justice Waters Of Nazareth (album version) Jacqueline Lynch\n",
      "Panic At The Disco Behind The Sea [Live In Chicago] Jacqueline Lynch\n",
      "Los LÃÂ¡tigos Besos Y Caricias Jacqueline Lynch\n",
      "Sick Puppies Maybe Jacqueline Lynch\n",
      "David Crowder*Band I Saw The Light Jacqueline Lynch\n",
      "Supersister A Girl Named You Jacqueline Lynch\n",
      "Faith No More Last Cup Of Sorrow Jacqueline Lynch\n",
      "Jet Black Stare Rearview Mirror Jacqueline Lynch\n",
      "Muse Supermassive Black Hole (Twilight Soundtrack Version) Jacqueline Lynch\n",
      "Nikka Costa Just Because Jacqueline Lynch\n",
      "The Black Keys I'll Be Your Man Jacqueline Lynch\n",
      "ExposÃÂ© Let Me Be The One Jacqueline Lynch\n",
      "Otis Rush Sit Down Baby Jacqueline Lynch\n",
      "Wavves So Bored Jacqueline Lynch\n",
      "Taking Back Sunday The Ballad Of Sal Villanueva (Album Version) Jacqueline Lynch\n",
      "Apocalyptica Quutamo Jacqueline Lynch\n",
      "Reel Big Fish Turn The Radio Off Jacqueline Lynch\n",
      "Love Shop En Nat Bliver Det Sommer Jacqueline Lynch\n",
      "Erin McKeown Fast As I Can Jacqueline Lynch\n",
      "Deadmau5 Slip Jacqueline Lynch\n",
      "Guns N' Roses The Garden Jacqueline Lynch\n",
      "Dntel I'd Like To Know Jacqueline Lynch\n",
      "Faron Young Hello Walls Jacqueline Lynch\n",
      "Fonseca Como Me Mira Jacqueline Lynch\n",
      "Goldfrapp Beautiful Jacqueline Lynch\n",
      "Hoobastank Up And Gone Jacqueline Lynch\n",
      "Various Artists - Delicious Vinyl Bust A Move Jacqueline Lynch\n",
      "Buena Vista Social Club La Bayamesa Jacqueline Lynch\n",
      "Train Marry Me Jacqueline Lynch\n",
      "Diam's Dans Ma Bulle (Edit Radio - Live 2006) Jacqueline Lynch\n",
      "Seal The Beginning (Single Remix) Jacqueline Lynch\n",
      "Flying Lotus Hello Jacqueline Lynch\n",
      "Belouis Some Imagination (12'' Version) Jacqueline Lynch\n",
      "The Fray Never Say Never Jacqueline Lynch\n",
      "Muse Sunburn [Live] Jacqueline Lynch\n",
      "Taylor Swift Love Story Jacqueline Lynch\n",
      "Bobby Lee Be Aware Jacqueline Lynch\n",
      "Great White House Of Broken Love Jacqueline Lynch\n",
      "Boys Noize DonÃÂ´t Believe The Hype Jacqueline Lynch\n",
      "Katy Perry I Kissed A Girl Jacqueline Lynch\n",
      "Platero Y Tu Imanol Jacqueline Lynch\n",
      "Kim Carnes Crazy In The Night (Barking At Airplanes) Jacqueline Lynch\n",
      "Apollo 100 Joy Jacqueline Lynch\n",
      "The Black Keys Howlin\u0019 For You Jacqueline Lynch\n",
      "Gorod Disavow your God (Album Version) Jacqueline Lynch\n",
      "Jack Johnson Monsoon Jacqueline Lynch\n",
      "Caribou Odessa Jacqueline Lynch\n",
      "Los Originales De San Juan El Infeliz Jacqueline Lynch\n",
      "Weezer Photograph Jacqueline Lynch\n"
     ]
    }
   ],
   "source": [
    "##We are using select statement validate the data we inserted into the table\n",
    "\n",
    "query = select_by_userId_sessionId % (29, 589)\n",
    "print(query)\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "for row in rows:\n",
    "    #print(row)\n",
    "    print (row.artist, row.song, row.firstname, row.lastname)\n",
    "del rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query #3 : \n",
    "### Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "By looking at query #3, we know our customer sparkify is trying to find out all the users (with their first and last name) that has listened to a given song.  We know song is a must in the partition key.  But since song itself cannot uniquely identify a record, we need to include userId into the parition key.  Therefore, our primary key would be a composite key including song and userId.  \n",
    "\n",
    "Once we have our primary key determined, we need to only include the asking columns into our table.  \n",
    "\n",
    "So our table for query #3 looks like the following\n",
    "\n",
    "- song text\n",
    "- userId int\n",
    "- firstname text\n",
    "- lastname text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT firstName, lastName FROM music_history_by_song where song='All Hands Against His Own'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sample query giving 'All Hands Against His Own' as song title\n",
    "print(select_by_song % ('All Hands Against His Own'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open up the file and parse the data and insert into table line by line\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = insert_music_history_song\n",
    "        session.execute(query, (line[9], int(line[10]), line[1], line[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT firstName, lastName FROM music_history_by_song where song='Like you better dead'\n",
      "\n",
      "Jacqueline Lynch\n"
     ]
    }
   ],
   "source": [
    "#We are using select statement validate the data we inserted into the table\n",
    "\n",
    "query = select_by_song % \"Like you better dead\"\n",
    "print(query)\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "for row in rows:\n",
    "    #print(row)\n",
    "    print (row.firstname, row.lastname)\n",
    "del rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Drop the table to clear the development environment\n",
    "drop_tables(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the session and cluster connection¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
